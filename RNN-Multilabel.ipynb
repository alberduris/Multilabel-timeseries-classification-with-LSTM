{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label time series classification with LSTM \n",
    "\n",
    "#### Implementation of model for multi-label tims series classification as discussed in the following paper: <a href=\"https://arxiv.org/abs/1511.03677\"> Learning to diagnose with LSTM and RNNs</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from tensorflow.contrib import rnn\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper methods for reading and creating sequences of data for RNN/LSTM\n",
    "\n",
    "You may be need to modify these methods according to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"data_rnn_multilabel.csv\"\n",
    "feature_column_name = \"Feature\"\n",
    "class_column_name = \"Class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    data = pd.read_csv(file_path,header = 0)\n",
    "    data = data.iloc[0:10009,:] #Only first 10.009\n",
    "    return data \n",
    "\n",
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += (window_size // 2)\n",
    "        \n",
    "def extract_segments(data, window_size = 30):\n",
    "    segments = np.empty((0,window_size))\n",
    "    labels = np.empty((0))\n",
    "    for (start,end) in windows(data,window_size):\n",
    "        if(len(data[start:end]) == (window_size)):\n",
    "            signal = data.iloc[start:end][feature_column_name]\n",
    "            segments = np.vstack([segments, signal])\n",
    "            \n",
    "            #Label is MODAL (most_common) value in sequence\n",
    "            #Label is in onehot format\n",
    "            labels = np.append(labels,stats.mode(data.iloc[start:end][class_column_name])[0][0])\n",
    "    return segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size = 10\n",
    "'''\n",
    "MIMIC-III dataset can possibly be use to train and test the model. \n",
    "But beware this is not the data set used by the authors of the paper. \n",
    "For dataset description and format please see Section 3: Data Description in the paper.\n",
    "'''\n",
    "data = read_data(filename) #Pandas DF\n",
    "segments,labels = extract_segments(data, win_size)\n",
    "labels = np.asarray(pd.get_dummies(labels), dtype = np.int8)\n",
    "reshaped_segments = segments.reshape([len(segments),win_size,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segments shape: (2000, 10) \n",
      "First elem as example:\n",
      " [ 0.76385228  0.62054265  0.85255228  0.60326969  0.57533214  0.20306302\n",
      "  0.50424147  0.59451474  0.71279341  0.07645766] \n",
      "\n",
      "reshaped_segments shape: (2000, 10, 1) \n",
      "First elem as example:\n",
      " [[ 0.76385228]\n",
      " [ 0.62054265]\n",
      " [ 0.85255228]\n",
      " [ 0.60326969]\n",
      " [ 0.57533214]\n",
      " [ 0.20306302]\n",
      " [ 0.50424147]\n",
      " [ 0.59451474]\n",
      " [ 0.71279341]\n",
      " [ 0.07645766]] \n",
      "\n",
      "lables shape: (2000, 3) \n",
      "First elem as example:\n",
      " [0 1 0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('segments shape:',segments.shape,'\\nFirst elem as example:\\n',segments[0],'\\n')\n",
    "print('reshaped_segments shape:',reshaped_segments.shape,'\\nFirst elem as example:\\n',reshaped_segments[0],'\\n')\n",
    "print('lables shape:',labels.shape,'\\nFirst elem as example:\\n',labels[0],'\\n') #Remember: Label is modal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_split = np.random.rand(len(reshaped_segments)) < 0.80\n",
    "train_x = reshaped_segments[train_test_split]\n",
    "train_y = labels[train_test_split]\n",
    "test_x = reshaped_segments[~train_test_split]\n",
    "test_y = labels[~train_test_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.60793542]\n",
      " [ 0.00931542]\n",
      " [ 0.71178549]\n",
      " [ 0.99879496]\n",
      " [ 0.57842481]\n",
      " [ 0.6999442 ]\n",
      " [ 0.62030079]\n",
      " [ 0.2829745 ]\n",
      " [ 0.99434038]\n",
      " [ 0.90881374]]\n",
      "[0 0 1]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0,len(train_x))\n",
    "print(train_x[idx])\n",
    "print(train_y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "batch_size = 10\n",
    "total_batches = (train_x.shape[0]//batch_size)\n",
    "\n",
    "n_input = 1\n",
    "n_steps = 10\n",
    "n_hidden = 64\n",
    "n_classes = 3\n",
    "\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 162\n"
     ]
    }
   ],
   "source": [
    "print('Total batches: %d' % total_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input/Output placeholders for Tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "y_steps = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper methods \n",
    "\n",
    "Addition of Dropout and/or other modification to model architecture can be made in LSTM function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def LSTM(x, weight, bias):\n",
    "    cell = tf.contrib.rnn.LSTMCell(n_hidden,state_is_tuple = True)\n",
    "    multi_layer_cell = tf.contrib.rnn.MultiRNNCell([cell] * 2)\n",
    "    output, state = tf.nn.dynamic_rnn(multi_layer_cell, x, dtype = tf.float32)\n",
    "    output_flattened = tf.reshape(output, [-1, n_hidden])\n",
    "    output_logits = tf.add(tf.matmul(output_flattened,weight),bias)\n",
    "    output_all = tf.nn.sigmoid(output_logits)\n",
    "    output_reshaped = tf.reshape(output_all,[-1,n_steps,n_classes])\n",
    "    output_last = tf.gather(tf.transpose(output_reshaped,[1,0,2]), n_steps - 1)  \n",
    "    #output = tf.transpose(output, [1, 0, 2])\n",
    "    #last = tf.gather(output, int(output.get_shape()[0]) - 1)\n",
    "    #output_last = tf.nn.sigmoid(tf.matmul(last, weight) + bias)\n",
    "    return output_last, output_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function: Binary cross entropy and target replication \n",
    "\n",
    "Loss function used in the paper is a combination of two losses 1) average loss of each time step prediction 2) loss of the prediction calculated at the last time step. Alpha in the combined loss function is a hyper-parameter. See the <a href=\"https://arxiv.org/abs/1511.03677\">paper</a> for more information on target replication and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = weight_variable([n_hidden,n_classes])\n",
    "bias = bias_variable([n_classes])\n",
    "y_last, y_all = LSTM(x,weight,bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "#all_steps_cost=tf.reduce_mean(-tf.reduce_mean((y_steps * tf.log(y_all))+(1 - y_steps) * tf.log(1 - y_all),reduction_indices=1))\n",
    "all_steps_cost = -tf.reduce_mean((y_steps * tf.log(y_all))  + (1 - y_steps) * tf.log(1 - y_all))\n",
    "last_step_cost = -tf.reduce_mean((y * tf.log(y_last)) + ((1 - y) * tf.log(1 - y_last)))\n",
    "loss_function = (alpha * all_steps_cost) + ((1 - alpha) * last_step_cost)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score:  0.711319803191\n",
      "ROC AUC Score:  0.746158461839\n",
      "ROC AUC Score:  0.756713097237\n",
      "ROC AUC Score:  0.775873891406\n",
      "ROC AUC Score:  0.787036263956\n",
      "ROC AUC Score:  0.791886437325\n",
      "ROC AUC Score:  0.794910158415\n",
      "ROC AUC Score:  0.797292557798\n",
      "ROC AUC Score:  0.79871226322\n",
      "ROC AUC Score:  0.800318222841\n",
      "ROC AUC Score:  0.802036358787\n",
      "ROC AUC Score:  0.804460244981\n",
      "ROC AUC Score:  0.806972058262\n",
      "ROC AUC Score:  0.809247132546\n",
      "ROC AUC Score:  0.811631696184\n",
      "ROC AUC Score:  0.81357341637\n",
      "ROC AUC Score:  0.816073977403\n",
      "ROC AUC Score:  0.818698083555\n",
      "ROC AUC Score:  0.820917569853\n",
      "ROC AUC Score:  0.82266976121\n",
      "ROC AUC Score:  0.82475174408\n",
      "ROC AUC Score:  0.826626303345\n",
      "ROC AUC Score:  0.828265715926\n",
      "ROC AUC Score:  0.831055773995\n",
      "ROC AUC Score:  0.834382890453\n",
      "ROC AUC Score:  0.838287789669\n",
      "ROC AUC Score:  0.842151329332\n",
      "ROC AUC Score:  0.843671208363\n",
      "ROC AUC Score:  0.846298930295\n",
      "ROC AUC Score:  0.849817587297\n",
      "ROC AUC Score:  0.852941392214\n",
      "ROC AUC Score:  0.856690395347\n",
      "ROC AUC Score:  0.860157295813\n",
      "ROC AUC Score:  0.863392429131\n",
      "ROC AUC Score:  0.866034311734\n",
      "ROC AUC Score:  0.868408670259\n",
      "ROC AUC Score:  0.870758487291\n",
      "ROC AUC Score:  0.872081985376\n",
      "ROC AUC Score:  0.873395412834\n",
      "ROC AUC Score:  0.874864313711\n",
      "ROC AUC Score:  0.876168305615\n",
      "ROC AUC Score:  0.877340681629\n",
      "ROC AUC Score:  0.878473178268\n",
      "ROC AUC Score:  0.879554142863\n",
      "ROC AUC Score:  0.880661133428\n",
      "ROC AUC Score:  0.881288485187\n",
      "ROC AUC Score:  0.881992179348\n",
      "ROC AUC Score:  0.882862565404\n",
      "ROC AUC Score:  0.88350688135\n",
      "ROC AUC Score:  0.884071756084\n",
      "ROC AUC Score:  0.884386576035\n",
      "ROC AUC Score:  0.884721492976\n",
      "ROC AUC Score:  0.884794187088\n",
      "ROC AUC Score:  0.884824672462\n",
      "ROC AUC Score:  0.884652881903\n",
      "ROC AUC Score:  0.88531459193\n",
      "ROC AUC Score:  0.885582096916\n",
      "ROC AUC Score:  0.886288904901\n",
      "ROC AUC Score:  0.887796361925\n",
      "ROC AUC Score:  0.889300271042\n",
      "ROC AUC Score:  0.891184273201\n",
      "ROC AUC Score:  0.89282422047\n",
      "ROC AUC Score:  0.894627028074\n",
      "ROC AUC Score:  0.8968856951\n",
      "ROC AUC Score:  0.899296497451\n",
      "ROC AUC Score:  0.901256751895\n",
      "ROC AUC Score:  0.903622635036\n",
      "ROC AUC Score:  0.906124351039\n",
      "ROC AUC Score:  0.908662332118\n",
      "ROC AUC Score:  0.910678831974\n",
      "ROC AUC Score:  0.912611939359\n",
      "ROC AUC Score:  0.913902188736\n",
      "ROC AUC Score:  0.914621702494\n",
      "ROC AUC Score:  0.914851443245\n",
      "ROC AUC Score:  0.915420687157\n",
      "ROC AUC Score:  0.916228943193\n",
      "ROC AUC Score:  0.916433204413\n",
      "ROC AUC Score:  0.91695472267\n",
      "ROC AUC Score:  0.917606159598\n",
      "ROC AUC Score:  0.918168028343\n",
      "ROC AUC Score:  0.918518996491\n",
      "ROC AUC Score:  0.918883437043\n",
      "ROC AUC Score:  0.918811849339\n",
      "ROC AUC Score:  0.919116220371\n",
      "ROC AUC Score:  0.919162551663\n",
      "ROC AUC Score:  0.919020020262\n",
      "ROC AUC Score:  0.918174957231\n",
      "ROC AUC Score:  0.917330126032\n",
      "ROC AUC Score:  0.915768431125\n",
      "ROC AUC Score:  0.914080773103\n",
      "ROC AUC Score:  0.912631812711\n",
      "ROC AUC Score:  0.911236342996\n",
      "ROC AUC Score:  0.909573776057\n",
      "ROC AUC Score:  0.908358167785\n",
      "ROC AUC Score:  0.90753498908\n",
      "ROC AUC Score:  0.906584927052\n",
      "ROC AUC Score:  0.905197093805\n",
      "ROC AUC Score:  0.904232317216\n",
      "ROC AUC Score:  0.903466583263\n",
      "ROC AUC Score:  0.902605101224\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(training_epochs):\n",
    "        for b in range(total_batches):    \n",
    "            offset = (b * batch_size) % (train_y.shape[0] - batch_size)\n",
    "            batch_x = train_x[offset:(offset + batch_size), :]\n",
    "            batch_y = train_y[offset:(offset + batch_size), :]\n",
    "            batch_y_steps = np.tile(batch_y,((train_x.shape[1]),1))\n",
    "            _, c = session.run([optimizer, loss_function],feed_dict={x: batch_x, y : batch_y, y_steps: batch_y_steps})   \n",
    "        pred_y = session.run(y_last,feed_dict={x:test_x})\n",
    "        print(\"ROC AUC Score: \",roc_auc_score(test_y,pred_y))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
